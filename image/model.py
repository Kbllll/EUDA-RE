import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, TensorDataset
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
import numpy as np
from tqdm import tqdm



from dataload import load_dataset


# ========================
# CNN æ¨¡å‹å®šä¹‰
# ========================
class CNNClassifier(nn.Module):
    def __init__(self, input_shape, num_classes):
        super(CNNClassifier, self).__init__()
        H, W, C = input_shape

        # å·ç§¯å±‚
        self.conv1 = nn.Conv2d(C, 32, kernel_size=3, padding=1)
        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)
        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)

        # æ± åŒ–å±‚ï¼ˆç‹¬ç«‹å®šä¹‰ï¼‰
        self.pool1 = nn.MaxPool2d(2)  # ç¬¬ä¸€å—å
        self.pool2 = nn.MaxPool2d(2)  # ç¬¬äºŒå—å
        self.pool3 = nn.MaxPool2d(2)  # ç¬¬ä¸‰å—åï¼ˆæ¡ä»¶ä½¿ç”¨ï¼‰

        self.use_pool3 = H >= 32  # ä»… 32x32 å›¾åƒä½¿ç”¨ç¬¬ä¸‰æ¬¡æ± åŒ–

        # è®¡ç®—å±•å¹³ç»´åº¦ï¼ˆé€šè¿‡å‰å‘ dummy passï¼‰
        with torch.no_grad():
            x = torch.zeros(1, C, H, W)
            x = torch.relu(self.conv1(x))
            x = self.pool1(x)
            x = torch.relu(self.conv2(x))
            x = self.pool2(x)
            x = torch.relu(self.conv3(x))
            if self.use_pool3:
                x = self.pool3(x)
            self.flattened_size = x.view(1, -1).size(1)

        # å…¨è¿æ¥å±‚
        self.fc1 = nn.Linear(self.flattened_size, 128)
        self.dropout = nn.Dropout(0.5)
        self.fc2 = nn.Linear(128, num_classes)

    def forward(self, x):
        x = torch.relu(self.conv1(x))
        x = self.pool1(x)
        x = torch.relu(self.conv2(x))
        x = self.pool2(x)
        x = torch.relu(self.conv3(x))
        if self.use_pool3:
            x = self.pool3(x)
        x = x.view(x.size(0), -1)  # å±•å¹³
        x = torch.relu(self.fc1(x))
        x = self.dropout(x)
        x = self.fc2(x)
        return x


# ========================
# è®­ç»ƒå‡½æ•°
# ========================
def train_cnn(
        X=None,
        y=None,
        img_shape=None,
        num_classes=None,
        test_size=0.2,
        random_state=42,
        epochs=20,
        batch_size=32,
        lr=0.001,
        device=None
):
    """
    ä½¿ç”¨ PyTorch è®­ç»ƒ CNN åˆ†ç±»å™¨

    Args:
        dataset_name: "Digits", "ORL32", "Yale32"
        device: 'cpu' æˆ– 'cuda'ï¼ˆé»˜è®¤è‡ªåŠ¨æ£€æµ‹ï¼‰
    """

    # è‡ªåŠ¨é€‰æ‹©è®¾å¤‡
    if device is None:
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"ğŸš€ ä½¿ç”¨è®¾å¤‡: {device}")

    print(f"  å›¾åƒå°ºå¯¸: {img_shape}, ç±»åˆ«æ•°: {num_classes}")

    # è½¬ä¸º PyTorch å¼ é‡ (N, C, H, W)
    X_tensor = torch.tensor(X, dtype=torch.float32).view(-1, 1, img_shape[0], img_shape[1])
    y_tensor = torch.tensor(y, dtype=torch.long)

    # åˆ†å±‚åˆ’åˆ†
    X_train, X_test, y_train, y_test = train_test_split(
        X_tensor, y_tensor,
        test_size=test_size,
        stratify=y,
        random_state=random_state
    )

    # åˆ›å»º DataLoader
    train_loader = DataLoader(TensorDataset(X_train, y_train), batch_size=batch_size, shuffle=True)
    test_loader = DataLoader(TensorDataset(X_test, y_test), batch_size=batch_size, shuffle=False)

    # åˆå§‹åŒ–æ¨¡å‹
    model = CNNClassifier(input_shape=(img_shape[0], img_shape[1], 1), num_classes=num_classes)
    model.to(device)

    # ä¼˜åŒ–å™¨ & æŸå¤±å‡½æ•°
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=lr)

    # è®­ç»ƒ
    model.train()
    # è®­ç»ƒå¾ªç¯
    bar = tqdm(range(epochs))
    train_losses, train_accs = [], []
    for _ in bar:
        train_loss, correct, total = 0, 0, 0
        for inputs, labels in train_loader:
            inputs, labels = inputs.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()

            train_loss += loss.item()
            _, predicted = torch.max(outputs.data, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()

        train_acc = 100 * correct / total
        train_losses.append(train_loss / len(train_loader))
        train_accs.append(train_acc)

        bar.set_postfix({
            "Loss": f"{train_losses[-1]:.4f}",
            "Train Acc": f"{train_acc:.2f}%"
        })


    # éªŒè¯
    model.eval()
    correct, total = 0, 0
    with torch.no_grad():
        for inputs, labels in test_loader:
            inputs, labels = inputs.to(device), labels.to(device)
            outputs = model(inputs)
            _, predicted = torch.max(outputs.data, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()
    test_acc = 100 * correct / total

    print(f"\nâœ… {dataset_name} æœ€ç»ˆæµ‹è¯•å‡†ç¡®ç‡: {test_acc:.2f}%")
    return model, device


